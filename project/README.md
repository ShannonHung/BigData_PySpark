
# Getting Start
- `data`: The folder contains all the data used in the project.
- `.code/1-Scaling-Observation.ipynb`: The jupyter notebook for testing the scaling of the data.
  - **TODO (Clara): Add the description of the RFM segmentation.**
- `.code/2-Fault-Tolerance.ipynb`: The jupyter notebook for testing the fault tolerance of the data.
  - Creating a cluster with 3 nodes. 
  - Testing with killing the java process of one of the nodes.
  - See if the cluster can still work and how the spark cluster handle the fault and achieve the fault tolerance. 
- `.code/3-RFM-Segmentation.ipynb`: The jupyter notebook for testing the RFM segmentation of the data.
  - **TODO (Niko): Add the description of the RFM segmentation.**

```bash 
.
├── data # all the data used in the project 
└── code
    ├── 1-Scaling-Observation.ipynb
    ├── 2-Fault-Tolerance.ipynb
    ├── 3-RFM-Segmentation.ipynb
    └── README.md
```


