{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import findspark \n",
    "findspark.init()\n",
    "\n",
    "# for sql\n",
    "from pyspark.sql import SparkSession \n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import sum,avg,max,count\n",
    "\n",
    "# for time \n",
    "import time \n",
    "import datetime as dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/28 22:25:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# 可以改成 *.csv \n",
    "root = '../../*.csv'\n",
    "spark = SparkSession.builder.appName('eCommerce').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "ecommerce = spark.read\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .csv(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecommerce.createOrReplaceTempView('ecommerce_2019_oct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- event_time: timestamp (nullable = true)\n",
      " |-- event_type: string (nullable = true)\n",
      " |-- product_id: integer (nullable = true)\n",
      " |-- category_id: long (nullable = true)\n",
      " |-- category_code: string (nullable = true)\n",
      " |-- brand: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- user_session: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ecommerce.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+----------+-------------------+--------------------+------+------+---------+--------------------+\n",
      "|         event_time|event_type|product_id|        category_id|       category_code| brand| price|  user_id|        user_session|\n",
      "+-------------------+----------+----------+-------------------+--------------------+------+------+---------+--------------------+\n",
      "|2019-11-01 01:00:00|      view|   1003461|2053013555631882655|electronics.smart...|xiaomi|489.07|520088904|4d3b30da-a5e4-49d...|\n",
      "|2019-11-01 01:00:00|      view|   5000088|2053013566100866035|appliances.sewing...|janome|293.65|530496790|8e5f4f83-366c-4f7...|\n",
      "|2019-11-01 01:00:01|      view|  17302664|2053013553853497655|                NULL| creed| 28.31|561587266|755422e7-9040-477...|\n",
      "|2019-11-01 01:00:01|      view|   3601530|2053013563810775923|appliances.kitche...|    lg|712.87|518085591|3bfb58cd-7892-48c...|\n",
      "|2019-11-01 01:00:01|      view|   1004775|2053013555631882655|electronics.smart...|xiaomi|183.27|558856683|313628f1-68b8-460...|\n",
      "+-------------------+----------+----------+-------------------+--------------------+------+------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ecommerce.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try with smaller (day) to larger size (months) and show when the time takes to long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Smaller days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_purchases = ecommerce.filter(col(\"event_type\") == 'purchase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+----------+-------------------+--------------------+-------+------+---------+--------------------+\n",
      "|         event_time|event_type|product_id|        category_id|       category_code|  brand| price|  user_id|        user_session|\n",
      "+-------------------+----------+----------+-------------------+--------------------+-------+------+---------+--------------------+\n",
      "|2019-11-01 01:00:41|  purchase|  13200605|2053013557192163841|furniture.bedroom...|   NULL| 566.3|559368633|d6034fa2-41fb-4ac...|\n",
      "|2019-11-01 01:01:04|  purchase|   1005161|2053013555631882655|electronics.smart...| xiaomi|211.92|513351129|e6b7ce9b-1938-4e2...|\n",
      "|2019-11-01 01:04:51|  purchase|   1004856|2053013555631882655|electronics.smart...|samsung|128.42|562958505|0f039697-fedc-40f...|\n",
      "|2019-11-01 01:05:34|  purchase|  26401669|2053013563651392361|                NULL|lucente|109.66|541854711|c41c44d5-ef9b-41b...|\n",
      "|2019-11-01 01:06:33|  purchase|   1801881|2053013554415534427|electronics.video.tv|samsung| 488.8|557746614|4d76d6d3-fff5-488...|\n",
      "+-------------------+----------+----------+-------------------+--------------------+-------+------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "only_purchases.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 19141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_price_specified_period: [Row(avg(price)=324.98067760305406)]\n",
      "Average price for specified period (2019-10-01 00:00:00 to 2019-10-02 00:00:00): 324.98067760305406\n",
      "Time taken: 79.66258406639099 sec\n"
     ]
    }
   ],
   "source": [
    "start_date = dt.datetime(2019,10,1)\n",
    "end_date = dt.datetime(2019,10,2)\n",
    "\n",
    "# filter data by date peirod \n",
    "specified_period = only_purchases.filter((col(\"event_time\") >= start_date) & (col(\"event_time\") < end_date))\n",
    "\n",
    "# count number of rows\n",
    "print(f'Number of rows: {specified_period.count()}')\n",
    "\n",
    "start = time.time() \n",
    "# calculate average price for specified period\n",
    "average_price_specified_period = specified_period.agg(avg(\"price\")).collect()\n",
    "print(f'average_price_specified_period: {average_price_specified_period}')\n",
    "print(f'Average price for specified period ({start_date} to {end_date}): {average_price_specified_period[0][0]}')\n",
    "print(f'Time taken: {time.time() - start} sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- larger size (whole month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 1659788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:===================================================>  (105 + 5) / 110]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 742752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# count number of rows\n",
    "oct30_date = dt.datetime(2019,10,31,23,59,59)\n",
    "print(f'Number of rows: {only_purchases.count()}')\n",
    "all_oct_purchases = only_purchases.filter(col(\"event_time\") <= oct30_date)\n",
    "print(f'Number of rows: {all_oct_purchases.count()}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:===================================================>  (105 + 5) / 110]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum event time: 2019-10-31 23:59:06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Use F.max for PySpark's max function\n",
    "max_event_time = all_oct_purchases.agg(F.max(\"event_time\")).collect()\n",
    "print(f\"Maximum event time: {max_event_time[0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:===================================================>  (105 + 5) / 110]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum event time: 2019-12-01 00:59:44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Use F.max for PySpark's max function\n",
    "max_event_time = only_purchases.agg(F.max(\"event_time\")).collect()\n",
    "print(f\"Maximum event time: {max_event_time[0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:====================================================> (106 + 4) / 110]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_proce_all: [Row(avg(price)=309.55203582083766)]\n",
      "Average price for whole period: 309.55203582083766\n",
      "Time taken: 83.80692100524902 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.time() \n",
    "# calculate average price for specified period\n",
    "average_proce_all = all_oct_purchases.agg(avg(\"price\")).collect()\n",
    "print(f'average_proce_all: {average_proce_all}')\n",
    "print(f'Average price for whole period: {average_proce_all[0][0]}')\n",
    "print(f'Time taken: {time.time() - start} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_data = only_purchases.groupBy(\"user_session\") \\\n",
    "    .agg(\n",
    "        F.max(\"event_time\").alias(\"Date_order\"),\n",
    "        F.collect_set(\"user_id\").alias(\"user_id\"),  # Unique user_ids\n",
    "        F.count(\"user_session\").alias(\"Quantity\"),\n",
    "        F.sum(\"price\").alias(\"money_spent\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:=====================================================>(108 + 2) / 110]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----------+--------+-----------+\n",
      "|        user_session|         Date_order|    user_id|Quantity|money_spent|\n",
      "+--------------------+-------------------+-----------+--------+-----------+\n",
      "|000081ea-9376-4eb...|2019-10-24 11:08:58|[513622224]|       1|     131.51|\n",
      "|0000c091-07d6-42b...|2019-11-18 13:48:57|[561759158]|       2|     617.26|\n",
      "|0000c1d0-0429-4e0...|2019-11-07 17:58:19|[568649822]|       1|      68.97|\n",
      "|000174ac-0ea3-402...|2019-10-18 12:46:20|[548449052]|       2|     499.72|\n",
      "|0001b5b4-ee2c-4ce...|2019-10-05 12:06:02|[523941620]|       1|      34.88|\n",
      "|0001d2b9-c9cc-474...|2019-11-05 11:08:48|[567769006]|       1|     915.85|\n",
      "|0001ff74-ac24-42d...|2019-11-17 18:34:04|[532345357]|       1|     395.35|\n",
      "|0002b07c-85cd-46e...|2019-10-14 12:04:26|[553453794]|       2|     366.54|\n",
      "|00031054-0bd7-4c3...|2019-11-16 13:19:56|[525362834]|       1|     298.28|\n",
      "|000312ec-17f5-466...|2019-11-22 10:07:52|[513531928]|       1|      90.09|\n",
      "|00035f1a-f4f4-417...|2019-11-14 05:39:11|[512639704]|       1|      89.81|\n",
      "|00040234-87dc-459...|2019-10-10 19:19:32|[558511295]|       1|     390.88|\n",
      "|0004289c-4ac6-418...|2019-10-15 16:20:42|[541376977]|       1|     360.34|\n",
      "|0004400f-dc39-410...|2019-10-16 07:24:33|[550005829]|       1|     143.63|\n",
      "|0004c309-ff34-44b...|2019-10-13 13:59:14|[547022478]|       2|      281.2|\n",
      "|00054650-f6f6-4d5...|2019-11-28 11:44:09|[562118653]|       1|    1929.26|\n",
      "|0005a967-3c02-459...|2019-11-03 17:40:08|[551699413]|       1|     724.34|\n",
      "|0005d01d-babe-40d...|2019-10-23 13:09:13|[514979424]|       1|     257.15|\n",
      "|00060054-401d-4d3...|2019-11-09 13:35:46|[565817990]|       1|     656.36|\n",
      "|0006ff50-ab19-4a7...|2019-11-17 17:14:05|[513938572]|       1|     561.66|\n",
      "+--------------------+-------------------+-----------+--------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "aggregated_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 28:=====================================================>(108 + 2) / 110]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-----------+--------+-----------+-------------+\n",
      "|        user_session|Date_order|    user_id|Quantity|money_spent|last_purchase|\n",
      "+--------------------+----------+-----------+--------+-----------+-------------+\n",
      "|000081ea-9376-4eb...|2019-10-24|[513622224]|       1|     131.51|           38|\n",
      "|0000c091-07d6-42b...|2019-11-18|[561759158]|       2|     617.26|           13|\n",
      "|0000c1d0-0429-4e0...|2019-11-07|[568649822]|       1|      68.97|           24|\n",
      "|000174ac-0ea3-402...|2019-10-18|[548449052]|       2|     499.72|           44|\n",
      "|0001b5b4-ee2c-4ce...|2019-10-05|[523941620]|       1|      34.88|           57|\n",
      "|0001d2b9-c9cc-474...|2019-11-05|[567769006]|       1|     915.85|           26|\n",
      "|0001ff74-ac24-42d...|2019-11-17|[532345357]|       1|     395.35|           14|\n",
      "|0002b07c-85cd-46e...|2019-10-14|[553453794]|       2|     366.54|           48|\n",
      "|00031054-0bd7-4c3...|2019-11-16|[525362834]|       1|     298.28|           15|\n",
      "|000312ec-17f5-466...|2019-11-22|[513531928]|       1|      90.09|            9|\n",
      "|00035f1a-f4f4-417...|2019-11-14|[512639704]|       1|      89.81|           17|\n",
      "|00040234-87dc-459...|2019-10-10|[558511295]|       1|     390.88|           52|\n",
      "|0004289c-4ac6-418...|2019-10-15|[541376977]|       1|     360.34|           47|\n",
      "|0004400f-dc39-410...|2019-10-16|[550005829]|       1|     143.63|           46|\n",
      "|0004c309-ff34-44b...|2019-10-13|[547022478]|       2|      281.2|           49|\n",
      "|00054650-f6f6-4d5...|2019-11-28|[562118653]|       1|    1929.26|            3|\n",
      "|0005a967-3c02-459...|2019-11-03|[551699413]|       1|     724.34|           28|\n",
      "|0005d01d-babe-40d...|2019-10-23|[514979424]|       1|     257.15|           39|\n",
      "|00060054-401d-4d3...|2019-11-09|[565817990]|       1|     656.36|           22|\n",
      "|0006ff50-ab19-4a7...|2019-11-17|[513938572]|       1|     561.66|           14|\n",
      "+--------------------+----------+-----------+--------+-----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import DateType\n",
    "import datetime as dt\n",
    "\n",
    "# Assuming 'data' is your PySpark DataFrame and 'Date_order' is a string column\n",
    "study_date = dt.datetime(2019, 12, 1)\n",
    "\n",
    "# Convert 'Date_order' to date type if it's not already\n",
    "data = aggregated_data.withColumn(\"Date_order\", F.col(\"Date_order\").cast(DateType()))\n",
    "\n",
    "# Calculate the difference in days\n",
    "data = data.withColumn(\"last_purchase\", F.datediff(F.lit(study_date), \"Date_order\"))\n",
    "\n",
    "# Show the first few rows of the DataFrame\n",
    "data.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Recency – How recently did the customer purchase?\n",
    "(befor days bought)\n",
    "##### Frequency – How often do they purchase?\n",
    "(count times)\n",
    "##### Monetary Value – How much do they spend?\n",
    "(per person totally amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 33:===================>                                      (3 + 6) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+---------+------------------+\n",
      "|    user_id|Recency|Frequency|          Monetary|\n",
      "+-----------+-------+---------+------------------+\n",
      "|[548449052]|      1|       59|          19014.07|\n",
      "|[548193532]|     14|        1|           4113.36|\n",
      "|[563811837]|     38|        1|            319.34|\n",
      "|[542656673]|     13|       15|           4414.79|\n",
      "|[520186665]|     14|        1|           2187.16|\n",
      "|[512762475]|      2|        3| 542.8199999999999|\n",
      "|[525277709]|      7|        1|            230.89|\n",
      "|[527305704]|      6|        5| 970.6600000000001|\n",
      "|[543949146]|     30|        2|           1207.21|\n",
      "|[564353044]|      2|        5|            301.87|\n",
      "|[570572677]|     19|        1|             29.59|\n",
      "|[541788524]|      1|        5|            251.19|\n",
      "|[542941877]|     13|        4|           1111.23|\n",
      "|[570042604]|      9|        1|             36.04|\n",
      "|[513430054]|     58|        1|            463.02|\n",
      "|[514269533]|     33|        1|             138.2|\n",
      "|[545325482]|     17|       66|15926.309999999998|\n",
      "|[515127340]|     47|       11|2382.9399999999996|\n",
      "|[512796362]|     15|        4|1402.0499999999997|\n",
      "|[528141023]|     42|        4|           5018.15|\n",
      "+-----------+-------+---------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "RFM = data.groupBy(\"user_id\") \\\n",
    "    .agg(\n",
    "        F.min(\"last_purchase\").alias(\"Recency\"),\n",
    "        F.count(\"user_id\").alias(\"Frequency\"),\n",
    "        F.sum(\"money_spent\").alias(\"Monetary\")\n",
    "    )\n",
    "\n",
    "# Show the first few rows of the RFM DataFrame\n",
    "RFM.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
